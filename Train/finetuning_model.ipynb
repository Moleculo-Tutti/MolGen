{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "from DataPipeline.dataset import ZincSubgraphDataset, custom_collate\n",
    "from Model.GNN1 import ModelWithEdgeFeatures\n",
    "from Model.metrics import pseudo_accuracy_metric, pseudo_recall_for_each_class, pseudo_precision_for_each_class\n",
    "from Train.training import complete_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset encoded with size 7\n"
     ]
    }
   ],
   "source": [
    "datapath = Path('..') / 'DataPipeline/data/preprocessed_graph_no_I_Br_P.pt'\n",
    "dataset = ZincSubgraphDataset(data_path = datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=0, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load checkpoint\n",
    "encoding_size = 7\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = ModelWithEdgeFeatures(num_classes = encoding_size, in_channels=encoding_size, hidden_channels_list=[64, 128, 256, 512, 512], mlp_hidden_channels=512, edge_channels=4, use_dropout=False)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "checkpoint_path = Path('..') / 'Train' / 'checkpoint_epoch_96_balanced_10-4.pt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "checkpoint = {key: tensor.to(device) if isinstance(tensor, torch.Tensor) else tensor\n",
    "              for key, tensor in checkpoint.items()}\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1845 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m complete_training(model, optimizer, criterion, dataloader, device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m), n_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfinetuning_model\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding_size\u001b[39m=\u001b[39;49mencoding_size)\n",
      "File \u001b[1;32mc:\\Users\\goupi\\OneDrive - CentraleSupelec\\VSCODE\\Siena\\MolecularGen\\Molgen\\MolGen\\Train\\training.py:104\u001b[0m, in \u001b[0;36mcomplete_training\u001b[1;34m(model, optimizer, loss_function, loader, device, n_epochs, name, encoding_size, save)\u001b[0m\n\u001b[0;32m    101\u001b[0m training_history \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mavg_output_vector\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mavg_label_vector\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 104\u001b[0m     loss, avg_label_vector, avg_output_vector, avg_correct, mse \u001b[39m=\u001b[39m train(model, optimizer, loss_function, loader, device, epoch, encoding_size\u001b[39m=\u001b[39;49mencoding_size)\n\u001b[0;32m    105\u001b[0m     training_history \u001b[39m=\u001b[39m training_history\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: loss, \u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m: mse, \u001b[39m'\u001b[39m\u001b[39mavg_output_vector\u001b[39m\u001b[39m'\u001b[39m: avg_output_vector, \u001b[39m'\u001b[39m\u001b[39mavg_label_vector\u001b[39m\u001b[39m'\u001b[39m: avg_label_vector, \u001b[39m'\u001b[39m\u001b[39mavg_correct\u001b[39m\u001b[39m'\u001b[39m: avg_correct}, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m     \u001b[39m#save the model(all with optimizer step, the loss ) every 5 epochs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\goupi\\OneDrive - CentraleSupelec\\VSCODE\\Siena\\MolecularGen\\Molgen\\MolGen\\Train\\training.py:69\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_function, loader, device, epoch, encoding_size)\u001b[0m\n\u001b[0;32m     67\u001b[0m count_per_class_precision \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m precision_output[\u001b[39m1\u001b[39m]\n\u001b[0;32m     68\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 69\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     70\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m data\u001b[39m.\u001b[39mnum_graphs\n\u001b[0;32m     71\u001b[0m loss_value \u001b[39m=\u001b[39m total_loss \u001b[39m/\u001b[39m (data\u001b[39m.\u001b[39mnum_graphs \u001b[39m*\u001b[39m (progress_bar\u001b[39m.\u001b[39mlast_print_n \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\torch\\optim\\adamw.py:162\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    158\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    160\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 162\u001b[0m     adamw(params_with_grad,\n\u001b[0;32m    163\u001b[0m           grads,\n\u001b[0;32m    164\u001b[0m           exp_avgs,\n\u001b[0;32m    165\u001b[0m           exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m           max_exp_avg_sqs,\n\u001b[0;32m    167\u001b[0m           state_steps,\n\u001b[0;32m    168\u001b[0m           amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    169\u001b[0m           beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    170\u001b[0m           beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    171\u001b[0m           lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    172\u001b[0m           weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    173\u001b[0m           eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    174\u001b[0m           maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    175\u001b[0m           foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    176\u001b[0m           capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\torch\\optim\\adamw.py:219\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 219\u001b[0m func(params,\n\u001b[0;32m    220\u001b[0m      grads,\n\u001b[0;32m    221\u001b[0m      exp_avgs,\n\u001b[0;32m    222\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    223\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    224\u001b[0m      state_steps,\n\u001b[0;32m    225\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    226\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    227\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    228\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    229\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    230\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    231\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    232\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\torch\\optim\\adamw.py:273\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    270\u001b[0m param\u001b[39m.\u001b[39mmul_(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m weight_decay)\n\u001b[0;32m    272\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39;49madd_(grad, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta1)\n\u001b[0;32m    274\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "complete_training(model, optimizer, criterion, dataloader, device=torch.device('cuda:0'), n_epochs=5, name='finetuning_model', encoding_size=encoding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
