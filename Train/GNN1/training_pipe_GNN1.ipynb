{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "parent_parent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append(parent_parent_dir)\n",
    "\n",
    "from DataPipeline.dataset import ZincSubgraphDatasetStep, custom_collate_passive_add_feature\n",
    "from Model.GNN1 import ModelWithEdgeFeatures\n",
    "from Model.metrics import pseudo_accuracy_metric, pseudo_recall_for_each_class, pseudo_precision_for_each_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset encoded with size 7\n"
     ]
    }
   ],
   "source": [
    "datapath = Path('..') / '../DataPipeline/data/preprocessed_graph_no_I_Br_P.pt'\n",
    "dataset = ZincSubgraphDatasetStep(data_path = datapath, GNN_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=custom_collate_passive_add_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 7\n",
    "\n",
    "model = ModelWithEdgeFeatures(in_channels=encoding_size + 1, hidden_channels_list=[64, 128, 256, 512, 512], mlp_hidden_channels=512, edge_channels=4, num_classes=encoding_size, use_dropout=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Set up the loss function for multiclass \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "name = 'GNN1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(loader, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    mse_sum = 0\n",
    "    num_correct = 0\n",
    "    num_correct_recall = torch.zeros(encoding_size)\n",
    "    num_correct_precision = torch.zeros(encoding_size)\n",
    "    count_per_class_recall = torch.zeros(encoding_size)\n",
    "    count_per_class_precision = torch.zeros(encoding_size)\n",
    "    progress_bar = tqdm_notebook(loader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    avg_output_vector = np.zeros(encoding_size)  # Initialize the average output vector\n",
    "    avg_label_vector = np.zeros(encoding_size)  # Initialize the average label vector\n",
    "    total_graphs_processed = 0\n",
    "\n",
    "    \n",
    "\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        data = batch[0]\n",
    "        terminal_node_infos = batch[1]\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logit_out = model(data)\n",
    "        terminal_node_infos = terminal_node_infos.to(device)\n",
    "\n",
    "        out = F.softmax(logit_out, dim=1)\n",
    "        loss = criterion(logit_out, terminal_node_infos)\n",
    "        num_correct += pseudo_accuracy_metric(out.detach().cpu(), terminal_node_infos.detach().cpu(), random=True)\n",
    "\n",
    "        recall_output = pseudo_recall_for_each_class(out.detach().cpu(), terminal_node_infos.detach().cpu(), random=True)\n",
    "        precision_output = pseudo_precision_for_each_class(out.detach().cpu(), terminal_node_infos.detach().cpu(), random=True)\n",
    "        num_correct_recall += recall_output[0]\n",
    "        num_correct_precision += precision_output[0]\n",
    "        count_per_class_recall += recall_output[1]\n",
    "        count_per_class_precision += precision_output[1]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        loss_value = total_loss / (data.num_graphs * (progress_bar.last_print_n + 1))\n",
    "\n",
    "        # Compute MSE\n",
    "        mse = mean_squared_error(terminal_node_infos.detach().cpu(), out.detach().cpu())\n",
    "        mse_sum += mse * data.num_graphs\n",
    "        mse_value = mse_sum / (data.num_graphs * (progress_bar.last_print_n + 1))\n",
    "\n",
    "        # Update the average output vector\n",
    "        avg_output_vector += out.detach().cpu().numpy().mean(axis=0) * data.num_graphs\n",
    "        avg_label_vector += terminal_node_infos.detach().cpu().numpy().mean(axis=0) * data.num_graphs\n",
    "        total_graphs_processed += data.num_graphs\n",
    "        current_avg_output_vector = avg_output_vector / total_graphs_processed\n",
    "        current_avg_label_vector = avg_label_vector / total_graphs_processed\n",
    "        avg_correct = num_correct / total_graphs_processed\n",
    "        avg_correct_recall = num_correct_recall / count_per_class_recall\n",
    "        avg_correct_precision = num_correct_precision / count_per_class_precision\n",
    "        avg_f1 = 2 * (avg_correct_recall * avg_correct_precision) / (avg_correct_recall + avg_correct_precision)\n",
    "        progress_bar.set_postfix(loss=loss_value, mse=mse_value, avg_output_vector=current_avg_output_vector, \n",
    "                                 avg_label_vector=current_avg_label_vector, \n",
    "                                 avg_correct=avg_correct, num_correct=num_correct, \n",
    "                                 total_graphs_processed=total_graphs_processed, \n",
    "                                 avg_correct_precision=avg_correct_precision, \n",
    "                                 avg_correct_recall=avg_correct_recall, \n",
    "                                 avg_f1=avg_f1,\n",
    "                                 count_per_class_precision=count_per_class_precision,\n",
    "                                 count_per_class_recall=count_per_class_recall)\n",
    "\n",
    "\n",
    "    return total_loss / len(loader.dataset), current_avg_label_vector, current_avg_output_vector, avg_correct , avg_correct_precision, avg_correct_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of Model.metrics failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Anto\\anaconda3\\envs\\torch-geometric\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\Anto\\anaconda3\\envs\\torch-geometric\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Anto\\anaconda3\\envs\\torch-geometric\\Lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1004, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\Anto\\Documents\\stage\\MolGen\\Model\\metrics.py\", line 26\n",
      "    model output = torch.multinomial(model_output)\n",
      "          ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368e69382bd0408bac6eaa348b6395f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1845 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.56886243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026597f8c58144a09455f089b093840f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1845 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.56595221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db6b373d71413d9c295635aa5992e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1845 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe to save the training history\n",
    "training_history = pd.DataFrame(columns=['epoch', 'loss', 'avg_output_vector', 'avg_label_vector', 'avg_correct', 'precision', 'recall'])\n",
    "\n",
    "n_epochs = 250\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, avg_label_vector, avg_output_vector, avg_correct, avg_correct_precision, avg_correct_recall = train(loader, epoch)\n",
    "    training_history.loc[epoch] = [epoch, loss, avg_output_vector, avg_label_vector, avg_correct, avg_correct_precision, avg_correct_recall]\n",
    "\n",
    "    #save the model(all with optimizer step, the loss ) every 5 epochs\n",
    "\n",
    "    save_every_n_epochs = 5\n",
    "    if (epoch) % save_every_n_epochs == 1:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            # Add any other relevant information you want to save here\n",
    "        }\n",
    "        torch.save(checkpoint, './history_training/'+f'checkpoint_epoch_{epoch+1}_{name}.pt')\n",
    "        \n",
    "    #save the training history every 10 epochs\n",
    "    if epoch % 1 == 0:\n",
    "        training_history.to_csv(f\"training_history_{name}.csv\", index=False)\n",
    "    print(f'Epoch: {epoch}, Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
