{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "from Dataset_Creation.script_pairs_creation_with_torch import get_subgraph_with_terminal_nodes, smiles_to_torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZincSubgraphDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_list = torch.load(data_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        preprocessed_graph = self.data_list[idx]\n",
    "        \n",
    "        mol_size = len(preprocessed_graph.x)\n",
    "        num_atoms = random.choice(range(3, mol_size + 1))\n",
    "        subgraph, terminal_nodes, id_map = get_subgraph_with_terminal_nodes(preprocessed_graph, num_atoms)\n",
    "\n",
    "        subgraph.x[id_map[terminal_nodes[0]]][9] = 1\n",
    "\n",
    "        #get the embedding of all the first element of terminal_nodes[1] and make them into a list to take the mean, if terminal_nodes[1] empty make torch.zeros(10)\n",
    "        label_gnn1 = torch.zeros(10)\n",
    "        neighbor_atom_list = [neighbor[1] for neighbor in terminal_nodes[1]]\n",
    "\n",
    "        if len(neighbor_atom_list) != 0:\n",
    "            label_gnn1 += torch.mean(torch.stack(neighbor_atom_list, dim=0), dim=0)\n",
    "\n",
    "        subgraph.y = label_gnn1\n",
    "\n",
    "        return subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import random\n",
    "from torch_geometric.data import Dataset as geomDataset\n",
    "\n",
    "class ZincSubgraphDataset(geomDataset):\n",
    "    def __init__(self, root, data_path, transform=None, pre_transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.data_list = torch.load(data_path)\n",
    "        super(ZincSubgraphDataset, self).__init__(root, transform, pre_transform) \n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        preprocessed_graph = self.data_list[idx]\n",
    "        \n",
    "        mol_size = len(preprocessed_graph.x)\n",
    "        num_atoms = random.choice(range(3, mol_size + 1))\n",
    "        subgraph, terminal_nodes, id_map = get_subgraph_with_terminal_nodes(preprocessed_graph, num_atoms)\n",
    "\n",
    "        subgraph.x[id_map[terminal_nodes[0]]][9] = 1\n",
    "\n",
    "        label_gnn1 = torch.zeros(10)\n",
    "        neighbor_atom_list = [neighbor[1] for neighbor in terminal_nodes[1]]\n",
    "\n",
    "        if len(neighbor_atom_list) != 0:\n",
    "            label_gnn1 += torch.mean(torch.stack(neighbor_atom_list, dim=0), dim=0)\n",
    "\n",
    "        subgraph.y = label_gnn1\n",
    "\n",
    "        return subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('..') / 'Dataset_Creation/preprocessed_graph.pt'\n",
    "dataset = ZincSubgraphDataset(data_path = datapath, root='fdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 16:22:57  Samples:  3497\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 3.543     CPU time: 4.578\n",
      "/   _/                      v4.4.0\n",
      "\n",
      "Program: c:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9019 --control=9017 --hb=9016 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"915a24f9-0548-49ba-bdae-7ff7a6bee7d0\" --shell=9018 --transport=\"tcp\" --iopub=9020 --f=c:\\Users\\goupi\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-6060P19y4jU9Faff.json\n",
      "\n",
      "\u001b[31m3.542\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m..\\..\\..\\AppData\\Local\\Temp\\ipykernel_20896\\3692288471.py:1\u001b[0m\n",
      "└─ \u001b[31m3.534\u001b[0m _SingleProcessDataLoaderIter.__next__\u001b[0m  \u001b[2mtorch\\utils\\data\\dataloader.py:623\u001b[0m\n",
      "      [175 frames hidden]  \u001b[2mtorch, torch_geometric, <built-in>, _...\u001b[0m\n",
      "         \u001b[31m3.307\u001b[0m ZincSubgraphDataset.__getitem__\u001b[0m  \u001b[2mtorch_geometric\\data\\dataset.py:238\u001b[0m\n",
      "         └─ \u001b[31m3.286\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZincSubgraphDataset.get\u001b[0m  \u001b[2m..\\..\\..\\AppData\\Local\\Temp\\ipykernel_20896\\2631566380.py:15\u001b[0m\n",
      "            ├─ \u001b[31m3.093\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph_with_terminal_nodes\u001b[0m  \u001b[2mDataset_Creation\\script_pairs_creation_with_torch.py:164\u001b[0m\n",
      "            │  ├─ \u001b[33m1.534\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            │  ├─ \u001b[33m1.090\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph\u001b[0m  \u001b[2mDataset_Creation\\script_pairs_creation_with_torch.py:126\u001b[0m\n",
      "            │  │  ├─ \u001b[32m0.604\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            │  │  ├─ \u001b[92m\u001b[2m0.146\u001b[0m Data.__init__\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:407\u001b[0m\n",
      "            │  │  │     [44 frames hidden]  \u001b[2mtorch_geometric, <built-in>\u001b[0m\n",
      "            │  │  ├─ \u001b[92m\u001b[2m0.083\u001b[0m Data.x\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:807\u001b[0m\n",
      "            │  │  │     [10 frames hidden]  \u001b[2mtorch_geometric, _collections_abc\u001b[0m\n",
      "            │  │  └─ \u001b[92m\u001b[2m0.078\u001b[0m _VariableFunctionsClass.tensor\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            │  │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "            │  ├─ \u001b[92m\u001b[2m0.134\u001b[0m Random.shuffle\u001b[0m  \u001b[2mrandom.py:380\u001b[0m\n",
      "            │  │     [10 frames hidden]  \u001b[2mrandom, <built-in>\u001b[0m\n",
      "            │  ├─ \u001b[92m\u001b[2m0.134\u001b[0m Data.edge_index\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:811\u001b[0m\n",
      "            │  │     [10 frames hidden]  \u001b[2mtorch_geometric, _collections_abc\u001b[0m\n",
      "            │  ├─ \u001b[92m\u001b[2m0.077\u001b[0m Data.num_nodes\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:154\u001b[0m\n",
      "            │  │     [30 frames hidden]  \u001b[2mtorch_geometric, <built-in>, _collect...\u001b[0m\n",
      "            │  ├─ \u001b[92m\u001b[2m0.041\u001b[0m _VariableFunctionsClass.tensor\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "            │  └─ \u001b[92m\u001b[2m0.037\u001b[0m Tensor.tolist\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "            ├─ \u001b[92m\u001b[2m0.056\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            └─ \u001b[92m\u001b[2m0.055\u001b[0m Data.__setattr__\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:443\u001b[0m\n",
      "                  [30 frames hidden]  \u001b[2mtorch_geometric, <built-in>\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "from pyinstrument import Profiler\n",
    "\n",
    "profiler = Profiler()\n",
    "\n",
    "profiler.start()\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    i += 1\n",
    "    if i == 100:\n",
    "        break\n",
    "profiler.stop()\n",
    "\n",
    "print(profiler.output_text(unicode=True, color=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels_list, mlp_hidden_channels, num_classes=10):\n",
    "        super(ModelGCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        assert len(hidden_channels_list) == 6, \"hidden_channels_list must have 6 elements\"\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels_list[0])\n",
    "        self.conv2 = GCNConv(hidden_channels_list[0], hidden_channels_list[1])\n",
    "        self.conv3 = GCNConv(hidden_channels_list[1], hidden_channels_list[2])\n",
    "        self.conv4 = GCNConv(hidden_channels_list[2], hidden_channels_list[3])\n",
    "        self.conv5 = GCNConv(hidden_channels_list[3], hidden_channels_list[4])\n",
    "        self.conv6 = GCNConv(hidden_channels_list[4], hidden_channels_list[5])\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(hidden_channels_list[5], mlp_hidden_channels)\n",
    "        self.fc2 = torch.nn.Linear(mlp_hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv6(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Aggregation function to obtain graph embedding\n",
    "        x = global_add_pool(x, batch)\n",
    "\n",
    "        # Two-layer MLP for classification\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/7796 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[742, 10], edge_index=[2, 1596], edge_attr=[1596, 4], batch=[742], ptr=[33])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m n_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     loss \u001b[39m=\u001b[39m train(dataloader)\n\u001b[0;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m out \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m---> 29\u001b[0m terminal_node_infos \u001b[39m=\u001b[39m terminal_node_infos\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     30\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, terminal_node_infos)\n\u001b[0;32m     31\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model = ModelGCN(in_channels=10, hidden_channels_list=[16, 32, 64, 128, 256, 512], mlp_hidden_channels=128)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "#crossentropy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    mse_sum = 0\n",
    "    progress_bar = tqdm(loader, desc=\"Training\", unit=\"batch\")\n",
    "    i = 0\n",
    "\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        i += 1\n",
    "        data = batch\n",
    "        print(data)\n",
    "        terminal_node_infos = data.y\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        terminal_node_infos = terminal_node_infos.to(device)\n",
    "        loss = criterion(out, terminal_node_infos)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        loss_value = total_loss / (data.num_graphs * (progress_bar.last_print_n + 1))\n",
    "\n",
    "        # Compute MSE\n",
    "        mse = torch.mean((terminal_node_infos.detach().cpu() - out.detach().cpu()) ** 2)\n",
    "        mse_sum += mse * data.num_graphs\n",
    "        mse_value = mse_sum / (data.num_graphs * (progress_bar.last_print_n + 1))\n",
    "\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss_value, mse=mse_value)\n",
    "    return total_loss / len(loader.dataset)\n",
    "# Train the model\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(dataloader)\n",
    "    print(f'Epoch: {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
