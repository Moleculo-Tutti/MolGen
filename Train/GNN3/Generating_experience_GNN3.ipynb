{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_pipe_GNN3_utils import TrainGNN3\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import torch\n",
    "import json\n",
    "from visualize import plot_history_GNN3\n",
    "import torch.multiprocessing as mp\n",
    "import pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [12]])\n",
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m# separate the tensor in as many part as we need\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(split_index\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m] )\n\u001b[1;32m---> 12\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msplit(tensor_1d, split_index)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Convertir la liste résultante en un tenseur de dimension 2\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(batch)\n",
      "File \u001b[1;32mc:\\Users\\14nic\\Anaconda3\\envs\\my_env\\lib\\site-packages\\torch\\functional.py:189\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    184\u001b[0m         split, (tensor,), tensor, split_size_or_sections, dim\u001b[39m=\u001b[39mdim)\n\u001b[0;32m    185\u001b[0m \u001b[39m# Overwriting reason:\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# This dispatches to two ATen functions depending on the type of\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m# call here.\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49msplit(split_size_or_sections, dim)\n",
      "File \u001b[1;32mc:\\Users\\14nic\\Anaconda3\\envs\\my_env\\lib\\site-packages\\torch\\_tensor.py:803\u001b[0m, in \u001b[0;36mTensor.split\u001b[1;34m(self, split_size, dim)\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_VF\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m, split_size, dim)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 803\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_VF\u001b[39m.\u001b[39;49msplit_with_sizes(\u001b[39mself\u001b[39;49m, split_size, dim)\n",
      "\u001b[1;31mTypeError\u001b[0m: split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, not Tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Votre tenseur à une dimension\n",
    "tensor_1d = torch.tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,0,1])\n",
    "\n",
    "# Trouver l'indice du premier \"1\" après une séquence de \"0\" for all the tensor\n",
    "split_index = (tensor_1d == 1).nonzero()\n",
    "\n",
    "print(split_index)\n",
    "# separate the tensor in as many part as we need\n",
    "batch = torch.split(tensor_1d, split_index)\n",
    "\n",
    "# Convertir la liste résultante en un tenseur de dimension 2\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  6,  7,  9, 12])\n",
      "tensor([4, 3, 1, 2, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m lengths \u001b[39m=\u001b[39m split_indices \u001b[39m-\u001b[39m begin_indices_minus_1_flat\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(split_indices \u001b[39m-\u001b[39m begin_indices_minus_1_flat)\n\u001b[1;32m---> 15\u001b[0m \u001b[39mprint\u001b[39m(lengths\u001b[39m.\u001b[39;49msqueeze(dim \u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     16\u001b[0m list_length \u001b[39m=\u001b[39m lengths\u001b[39m.\u001b[39msqueeze(dim \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     17\u001b[0m \u001b[39m# Répéter les indices pour obtenir les positions de début et de fin\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[39m# Utiliser les indices pour extraire les parties correspondantes du tenseur\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# Votre tenseur à une dimension\n",
    "tensor_1d = torch.tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,0,0])\n",
    "\n",
    "# Trouver les indices où le changement de 0 à 1 se produit\n",
    "split_indices = (tensor_1d == 1).nonzero().flatten()\n",
    "\n",
    "\n",
    "# Ajouter l'indice de fin du tenseur\n",
    "\n",
    "# Calculer les longueurs des parties séparé\n",
    "print(split_indices)\n",
    "begin_indices_minus_1_flat = torch.cat([torch.tensor([-1]), split_indices[:-1]])\n",
    "lengths = split_indices - begin_indices_minus_1_flat\n",
    "print(split_indices - begin_indices_minus_1_flat)\n",
    "print(lengths.squeeze(dim =1))\n",
    "list_length = lengths.squeeze(dim =1).tolist()\n",
    "# Répéter les indices pour obtenir les positions de début et de fin\n",
    "\n",
    "# Utiliser les indices pour extraire les parties correspondantes du tenseur\n",
    "batch = torch.split(tensor_1d, list_length)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  5,  7,  9, 11])\n",
      "tensor([ 5,  7,  9, 11, 15])\n",
      "tensor([5, 2, 2, 2, 4])\n",
      "(tensor([0, 0, 0, 1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "#problème plus compliqué, en fait il y a juste un 1 par batch qui nous interesse mais il n est pas forcément à la fin\n",
    "# Votre tenseur à une dimension\n",
    "tensor_1d = torch.tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,0,0])\n",
    "\n",
    "appartenance_tensor = torch.tensor([0,0,0,0,0,1,1,2,2,3,3,4,4,4,4])\n",
    "\n",
    "# Trouver les indices où le changement de appartenance tensor prend + 1 se produit\n",
    "begin_indices= torch.cat([torch.tensor([0]), (appartenance_tensor[1:] != appartenance_tensor[:-1]).nonzero().flatten() + 1])\n",
    "print(begin_indices)\n",
    "\n",
    "\n",
    "end_indices = torch.cat([begin_indices[1:],torch.tensor([len(appartenance_tensor)])])\n",
    "print(end_indices)\n",
    "lengths = end_indices - begin_indices\n",
    "print(lengths)\n",
    "list_length = lengths.tolist()\n",
    "# Répéter les indices pour obtenir les positions de début et de fin\n",
    "\n",
    "# Utiliser les indices pour extraire les parties correspondantes du tenseur\n",
    "batch = torch.split(tensor_1d, list_length)\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path('config_GNN3.json')\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "        config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Loading data...\n",
      "Dataset encoded with size 13\n",
      "Dataset encoded with size 13\n",
      "Data loaded\n",
      "The 'GNN3_test_mem_leak' directory has been successfully created in the 'experiments' directory.\n"
     ]
    }
   ],
   "source": [
    "# Call the train_GNN3 function with the provided arguments\n",
    "mp.set_sharing_strategy('file_system') # Can cause memory leak\n",
    "\n",
    "TrainingGNN3 = TrainGNN3(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1559/1559 [08:05<00:00,  3.21batch/s]\n",
      "\n",
      "Evaluating: 100%|██████████| 195/195 [00:55<00:00,  3.52batch/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:55<00:00, 55.48s/it]\n",
      "Training: 100%|██████████| 1559/1559 [06:00<00:00,  4.33batch/s]\n",
      "100%|██████████| 2/2 [15:38<00:00, 469.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 12:47:09  Samples:  785709\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 938.364   CPU time: 2147.641\n",
      "/   _/                      v4.4.0\n",
      "\n",
      "Program: c:\\Users\\goupi\\.conda\\envs\\torch_geometric\\lib\\site-packages\\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"84944315-617f-4a63-b1d9-f97d8ff7267a\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=c:\\Users\\goupi\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-17988Q7cXCTYyzlDw.json\n",
      "\n",
      "\u001b[31m938.365\u001b[0m ZMQInteractiveShell.run_ast_nodes\u001b[0m  \u001b[2mIPython\\core\\interactiveshell.py:3301\u001b[0m\n",
      "└─ \u001b[31m938.359\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m..\\..\\..\\AppData\\Local\\Temp\\ipykernel_23828\\3376102744.py:1\u001b[0m\n",
      "   └─ \u001b[31m938.359\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTrainGNN3.train\u001b[0m  \u001b[2mtraining_pipe_GNN3_utils.py:333\u001b[0m\n",
      "      ├─ \u001b[31m845.254\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtrain_one_epoch\u001b[0m  \u001b[2mtraining_pipe_GNN3_utils.py:40\u001b[0m\n",
      "      │  ├─ \u001b[31m663.065\u001b[0m tqdm.__iter__\u001b[0m  \u001b[2mtqdm\\std.py:1174\u001b[0m\n",
      "      │  │     [332 frames hidden]  \u001b[2mtqdm, torch, <built-in>, ipykernel, t...\u001b[0m\n",
      "      │  │        \u001b[31m649.170\u001b[0m _MapDatasetFetcher.fetch\u001b[0m  \u001b[2mtorch\\utils\\data\\_utils\\fetch.py:53\u001b[0m\n",
      "      │  │        ├─ \u001b[31m620.135\u001b[0m <listcomp>\u001b[0m  \u001b[2mtorch\\utils\\data\\_utils\\fetch.py:58\u001b[0m\n",
      "      │  │        │  └─ \u001b[31m619.185\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZincSubgraphDatasetStep.__getitem__\u001b[0m  \u001b[2mDataPipeline\\dataset.py:72\u001b[0m\n",
      "      │  │        │     ├─ \u001b[33m447.464\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph_with_terminal_nodes_step\u001b[0m  \u001b[2mDataPipeline\\preprocessing.py:194\u001b[0m\n",
      "      │  │        │     │  ├─ \u001b[33m210.912\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │     │  ├─ \u001b[32m174.389\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph\u001b[0m  \u001b[2mDataPipeline\\preprocessing.py:155\u001b[0m\n",
      "      │  │        │     │  │  ├─ \u001b[32m95.305\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │     │  │  ├─ \u001b[92m\u001b[2m27.024\u001b[0m Data.__init__\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:407\u001b[0m\n",
      "      │  │        │     │  │  │     [52 frames hidden]  \u001b[2mtorch_geometric, <built-in>\u001b[0m\n",
      "      │  │        │     │  │  └─ \u001b[92m\u001b[2m12.338\u001b[0m _VariableFunctionsClass.tensor\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │     │  │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "      │  │        │     │  ├─ \u001b[92m\u001b[2m18.133\u001b[0m Data.edge_index\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:811\u001b[0m\n",
      "      │  │        │     │  │     [10 frames hidden]  \u001b[2mtorch_geometric, _collections_abc\u001b[0m\n",
      "      │  │        │     │  ├─ \u001b[92m\u001b[2m12.708\u001b[0m Data.num_nodes\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:154\u001b[0m\n",
      "      │  │        │     │  │     [32 frames hidden]  \u001b[2mtorch_geometric, <built-in>, _collect...\u001b[0m\n",
      "      │  │        │     │  └─ \u001b[92m\u001b[2m9.534\u001b[0m Random.shuffle\u001b[0m  \u001b[2mrandom.py:380\u001b[0m\n",
      "      │  │        │     │        [10 frames hidden]  \u001b[2mrandom, <built-in>\u001b[0m\n",
      "      │  │        │     ├─ \u001b[92m\u001b[2m40.172\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │     ├─ \u001b[92m\u001b[2m38.699\u001b[0m Data.__setattr__\u001b[0m  \u001b[2mtorch_geometric\\data\\data.py:443\u001b[0m\n",
      "      │  │        │     │     [32 frames hidden]  \u001b[2mtorch_geometric, <built-in>\u001b[0m\n",
      "      │  │        │     ├─ \u001b[92m\u001b[2m26.268\u001b[0m _VariableFunctionsClass.cat\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │     │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "      │  │        │     └─ \u001b[92m\u001b[2m9.824\u001b[0m RandomState.randint\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │        │           [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "      │  │        └─ \u001b[92m\u001b[2m29.020\u001b[0m \u001b[48;5;24m\u001b[38;5;15mcustom_collate_GNN3\u001b[0m  \u001b[2mDataPipeline\\dataset.py:258\u001b[0m\n",
      "      │  │           └─ \u001b[92m\u001b[2m25.321\u001b[0m Batch.from_data_list\u001b[0m  \u001b[2mtorch_geometric\\data\\batch.py:64\u001b[0m\n",
      "      │  │                 [316 frames hidden]  \u001b[2mtorch_geometric, <built-in>, _collect...\u001b[0m\n",
      "      │  ├─ \u001b[32m67.580\u001b[0m ModelWithgraph_embedding_modif._call_impl\u001b[0m  \u001b[2mtorch\\nn\\modules\\module.py:1188\u001b[0m\n",
      "      │  │     [14 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "      │  │        \u001b[32m67.096\u001b[0m \u001b[48;5;24m\u001b[38;5;15mModelWithgraph_embedding_modif.forward\u001b[0m  \u001b[2mModel\\GNN3.py:93\u001b[0m\n",
      "      │  │        ├─ \u001b[92m\u001b[2m42.388\u001b[0m global_add_pool\u001b[0m  \u001b[2mtorch_geometric\\nn\\pool\\glob.py:8\u001b[0m\n",
      "      │  │        │     [22 frames hidden]  \u001b[2mtorch_geometric, <built-in>\u001b[0m\n",
      "      │  │        └─ \u001b[92m\u001b[2m19.089\u001b[0m CustomMessagePassingLayer._call_impl\u001b[0m  \u001b[2mtorch\\nn\\modules\\module.py:1188\u001b[0m\n",
      "      │  │              [36 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "      │  │                 \u001b[92m\u001b[2m15.494\u001b[0m \u001b[48;5;24m\u001b[38;5;15mCustomMessagePassingLayer.forward\u001b[0m  \u001b[2mModel\\GNN3.py:13\u001b[0m\n",
      "      │  │                 └─ \u001b[92m\u001b[2m9.449\u001b[0m CustomMessagePassingLayer.propagate\u001b[0m  \u001b[2mtorch_geometric\\nn\\conv\\message_passing.py:359\u001b[0m\n",
      "      │  │                       [92 frames hidden]  \u001b[2mtorch_geometric, torch, <built-in>\u001b[0m\n",
      "      │  ├─ \u001b[92m\u001b[2m36.312\u001b[0m \u001b[48;5;24m\u001b[38;5;15mpseudo_accuracy_metric_gnn3\u001b[0m  \u001b[2mModel\\metrics.py:25\u001b[0m\n",
      "      │  │  └─ \u001b[92m\u001b[2m18.979\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  ├─ \u001b[92m\u001b[2m36.189\u001b[0m Tensor.item\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "      │  ├─ \u001b[92m\u001b[2m14.991\u001b[0m wrapper\u001b[0m  \u001b[2mtorch\\optim\\optimizer.py:135\u001b[0m\n",
      "      │  │     [42 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "      │  └─ \u001b[92m\u001b[2m13.638\u001b[0m Tensor.backward\u001b[0m  \u001b[2mtorch\\_tensor.py:429\u001b[0m\n",
      "      │        [26 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "      ├─ \u001b[32m55.491\u001b[0m \u001b[48;5;24m\u001b[38;5;15meval_one_epoch\u001b[0m  \u001b[2mtraining_pipe_GNN3_utils.py:139\u001b[0m\n",
      "      │  └─ \u001b[92m\u001b[2m45.078\u001b[0m tqdm.__iter__\u001b[0m  \u001b[2mtqdm\\std.py:1174\u001b[0m\n",
      "      │        [163 frames hidden]  \u001b[2mtqdm, torch, <built-in>, ipykernel, t...\u001b[0m\n",
      "      │           \u001b[92m\u001b[2m42.537\u001b[0m <listcomp>\u001b[0m  \u001b[2mtorch\\utils\\data\\_utils\\fetch.py:58\u001b[0m\n",
      "      │           └─ \u001b[92m\u001b[2m42.463\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZincSubgraphDatasetStep.__getitem__\u001b[0m  \u001b[2mDataPipeline\\dataset.py:72\u001b[0m\n",
      "      │              └─ \u001b[92m\u001b[2m31.179\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph_with_terminal_nodes_step\u001b[0m  \u001b[2mDataPipeline\\preprocessing.py:194\u001b[0m\n",
      "      │                 ├─ \u001b[92m\u001b[2m15.099\u001b[0m [self]\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "      │                 └─ \u001b[92m\u001b[2m11.965\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_subgraph\u001b[0m  \u001b[2mDataPipeline\\preprocessing.py:155\u001b[0m\n",
      "      └─ \u001b[92m\u001b[2m36.181\u001b[0m collect\u001b[0m  \u001b[2mNone\u001b[0m\n",
      "            [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Profile the training  \n",
    "\n",
    "profiler = pyinstrument.Profiler()\n",
    "\n",
    "profiler.start()\n",
    "TrainingGNN3.train()\n",
    "profiler.stop()\n",
    "\n",
    "print(profiler.output_text(unicode=True, color=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
