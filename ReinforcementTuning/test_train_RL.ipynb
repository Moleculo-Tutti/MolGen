{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from DataPipeline.preprocessing import node_encoder, tensor_to_smiles\n",
    "from generation import Sampling_Path_Batch\n",
    "from models import Model_GNNs\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GDCTrainer_path():\n",
    "    \n",
    "    def __init__(self, Module_Gen, features, desired_moments, q_update_criterion, lr = 1e-4, minibatch_size = 16, batch_size = 1000, min_nabla_lambda = 0.01, lambdas = None):\n",
    "   \n",
    "        # dpg_epochs is the number of optimization epochs per batch of samples\n",
    "        self.Module_Gen = Module_Gen\n",
    "        self.Module_Gen.batch_size = batch_size\n",
    "        self.features = features\n",
    "\n",
    "        if lambdas is None:\n",
    "            self.lambdas = torch.zeros(len(self.features)).to(self.Module_Gen.device)\n",
    "        else:\n",
    "            self.lambdas = lambdas.to(self.Module_Gen.device)\n",
    "        Module_Gen.lambdas = self.lambdas # Be sure that the lambdas are initialized to 0 in Module_Gen\n",
    "        self.q_update_criterion = q_update_criterion\n",
    "        self.batch_size = batch_size\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.desired_moments = desired_moments\n",
    "        self.min_nabla_lambda =  min_nabla_lambda      # difference between the wanted mu and approximated mu \n",
    "\n",
    "        assert self.q_update_criterion in ['interval', 'tvd', \"kld\"]\n",
    "        # q_update_criterion can take one of the following values:\n",
    "        # - 'interval': Update the GDP policy at regular intervals defined by q_update_interval.\n",
    "        # - 'tvd': Update the GDP policy when the total variation distance between action probability distributions exceeds a threshold.\n",
    "        # - 'kld': Update the GDP policy when the Kullback-Leibler divergence between action probability distributions exceeds a threshold.\n",
    "        \n",
    "\n",
    "        # GNN1_model\n",
    "        for p1, p2 in zip(self.Module_Gen.GNNs_Models_q.GNN1_model.parameters(), self.Module_Gen.GNNs_Models_a.GNN1_model.parameters()):\n",
    "            p1.requires_grad = False\n",
    "            p2.requires_grad = False\n",
    "        \n",
    "        # GNN2_model\n",
    "        for p1, p2 in zip(self.Module_Gen.GNNs_Models_q.GNN2_model.parameters(), self.Module_Gen.GNNs_Models_a.GNN2_model.parameters()):\n",
    "            p1.requires_grad = False\n",
    "            p2.requires_grad = False\n",
    "        \n",
    "        #GNN3_1_model\n",
    "        for p1, p2 in zip(self.Module_Gen.GNNs_Models_q.GNN3_1_model.parameters(), self.Module_Gen.GNNs_Models_a.GNN3_1_model.parameters()):\n",
    "            p1.requires_grad = False\n",
    "            p2.requires_grad = False\n",
    "        \n",
    "        #GNN3_2_model\n",
    "        for p1, p2 in zip(self.Module_Gen.GNNs_Models_q.GNN3_2_model.parameters(), self.Module_Gen.GNNs_Models_a.GNN3_2_model.parameters()):\n",
    "            p1.requires_grad = False\n",
    "            p2.requires_grad = False\n",
    "\n",
    "        # Define optimizers \n",
    "        self.optimizer_1 = torch.optim.Adam(self.Module_Gen.GNNs_Models_pi.GNN1_model.parameters(), lr=lr)\n",
    "        self.optimizer_2 = torch.optim.Adam(self.Module_Gen.GNNs_Models_pi.GNN2_model.parameters(), lr=lr)\n",
    "        self.optimizer_3_1 = torch.optim.Adam(self.Module_Gen.GNNs_Models_pi.GNN3_1_model.parameters(), lr=lr)\n",
    "        self.optimizer_3_2 = torch.optim.Adam(self.Module_Gen.GNNs_Models_pi.GNN3_2_model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "        # will hold all values of P(x) / q(x) for estimating TVD\n",
    "        self.Z_moving_average = 0\n",
    "        self.iter = 0\n",
    "        self.min_kld = float(\"inf\")\n",
    "        self.min_tvd = float(\"inf\")\n",
    "        self.is_policy_eval = False\n",
    "\n",
    "        #### Compute lambdas\n",
    "        if lambdas is None:\n",
    "            self.compute_optimal_lambdas()\n",
    "\n",
    "\n",
    "    def compute_optimal_lambdas(self, sample_size=5, n_iters=1000, lr=.5, min_nabla_lambda = 0.001): #how do they define the learning rate and sample size maybe do more\n",
    "        \"\"\"\n",
    "        This performs the first step: Constraints --> EBM through self-normalized importance sampling. \n",
    "        Args:\n",
    "            sample_size: total number of samples to use for lambda computation\n",
    "        Returns:\n",
    "            dicitonary of optimal lambdas per constraint: {'black': lambda_1, 'positive': lambda_2}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        print(\"Computing Optimal Lambdas for desired moments...\")\n",
    "\n",
    "        max_n_iters = n_iters\n",
    "\n",
    "        feature_names = list(self.Module_Gen.features.keys())\n",
    "        mu_star = self.desired_moments #name mu_bar in the pseudo code\n",
    "\n",
    "        mu_star = torch.tensor([mu_star[f] for f in feature_names])\n",
    "        lambdas = self.Module_Gen.lambdas.cpu()\n",
    "\n",
    "        # Collect sample_size samples for this:\n",
    "        list_feature_tensor = []\n",
    "        for i in range(sample_size):\n",
    "            #if we do multi processing, i think here the best \n",
    "            #put pi without grad for lambdas\n",
    "\n",
    "            self.Module_Gen.full_generation()\n",
    "            self.Module_Gen.convert_to_smiles()\n",
    "            self.Module_Gen.compute_features()\n",
    "\n",
    "            batch_features_values = self.Module_Gen.all_features_values\n",
    "\n",
    "            \n",
    "            list_feature_tensor.append(batch_features_values)\n",
    "\n",
    "        all_feature_tensor = torch.cat(list_feature_tensor, dim=0)  # [sample_sz*size_batch x F]\n",
    "\n",
    "        #### check for zero-occuring features. \n",
    "        # If a constraint has not occurred in your sample, no lambdas will be learned for that constraint, so we must check.\n",
    "\n",
    "        for i, feature  in enumerate(feature_names):\n",
    "            assert all_feature_tensor[:, i].sum().item() > 0, \"constraint {feature} hasn't occurred in the samples, use a larger sample size\"\n",
    "\n",
    "        for step in range(max_n_iters): #SGD for finding lambdas\n",
    "\n",
    "            # 1. calculate P_over_q batch wise with current lambdas which will be name w\n",
    "            ## compute new exponents\n",
    "\n",
    "            w = torch.exp(torch.matmul(all_feature_tensor, lambdas.to(all_feature_tensor.device)))\n",
    "\n",
    "\n",
    "            # 2. compute mu (mean) of features given the current lambda using SNIS\n",
    "            mu_lambda_numerator = w.view(1, -1).matmul(all_feature_tensor ).squeeze(0) # F\n",
    "            mu_lambda_denominator = w.sum()\n",
    "            mu_lambda = mu_lambda_numerator / mu_lambda_denominator # F\n",
    "\n",
    "            # 3. Update current Lambdas\n",
    "            nabla_lambda = mu_star - mu_lambda.cpu()\n",
    "            err = np.linalg.norm(nabla_lambda.cpu().numpy())\n",
    "            print(\"step: %s \\t ||nabla_lambda|| = %.6f\" %(step, err))\n",
    "            lambdas = lambdas + lr * nabla_lambda\n",
    "            print(\"\\tlambdas : {} \".format(self.Module_Gen.lambdas))\n",
    "            print(\"\\tμ: {}\".format(mu_lambda))\n",
    "            print(\"\\tμ*: {}\".format(mu_star))\n",
    "\n",
    "            self.Module_Gen.lambdas = lambdas\n",
    "            \n",
    "            ## Check if error is less than tolerance, then break.\n",
    "            if err < min_nabla_lambda: \n",
    "                break\n",
    "    \n",
    "\n",
    "    def step(self, num_batches, num_mini_batches):\n",
    "        train_stats = {}\n",
    "        P_over_q = []\n",
    "        P_over_pi = []\n",
    "        pi_over_q = []\n",
    "        total_loss = 0\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            for k in tqdm(range(num_mini_batches)):\n",
    "                loss = 0\n",
    "                self.optimizer_1.zero_grad()\n",
    "                self.optimizer_2.zero_grad()\n",
    "                self.optimizer_3_1.zero_grad()\n",
    "                self.optimizer_3_2.zero_grad()\n",
    "\n",
    "                self.Module_Gen.full_generation(batch_size = self.minibatch_size)\n",
    "                self.Module_Gen.convert_to_smiles()\n",
    "                self.Module_Gen.compute_features()\n",
    "                \n",
    "                exponents, all_features_values, q_value, a_value, pi_value = self.Module_Gen.get_all()\n",
    "\n",
    "                # Check if there is a zero in the tensor q, a or pi\n",
    "\n",
    "                if (q_value == 0).any():\n",
    "                    print(q_value)\n",
    "\n",
    "                if (a_value == 0).any():\n",
    "                    print(a_value)\n",
    "                \n",
    "                if (pi_value == 0).any():\n",
    "                    print(pi_value)\n",
    "\n",
    "                assert self.Module_Gen.GNNs_Models_q.GNN1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_q.GNN2_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_q.GNN3_1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_q.GNN3_2_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_pi.GNN1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_pi.GNN2_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_pi.GNN3_1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_pi.GNN3_2_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_a.GNN1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_a.GNN2_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_a.GNN3_1_model.training == False\n",
    "                assert self.Module_Gen.GNNs_Models_a.GNN3_2_model.training == False\n",
    "                \n",
    "\n",
    "                P_over_q.append(torch.flatten(a_value * exponents / q_value))\n",
    "                P_over_pi.append(torch.flatten(a_value * exponents / pi_value))\n",
    "                pi_over_q.append(torch.flatten(pi_value / q_value))\n",
    "\n",
    "                # Compute the loss to train the model\n",
    "                loss = - torch.sum(a_value*exponents / q_value * torch.log(pi_value))\n",
    "                total_loss += loss.item()   \n",
    "\n",
    "                # Backward pass and optimizer steps are performed after each mini-batch\n",
    "                loss.backward()\n",
    "                self.optimizer_1.step()\n",
    "                self.optimizer_2.step()\n",
    "                self.optimizer_3_1.step()\n",
    "                self.optimizer_3_2.step()\n",
    "\n",
    "                self.Module_Gen.clean_memory()\n",
    "\n",
    "                \"\"\"\n",
    "                # Delete everything that is not needed anymore\n",
    "                loss.cpu().detach()\n",
    "                q_value.cpu().detach()\n",
    "                a_value.cpu().detach()\n",
    "                pi_value.cpu().detach()\n",
    "                exponents.cpu().detach()\n",
    "                del loss, q_value, a_value, pi_value, exponents\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # Garbage collection\n",
    "                gc.collect()\n",
    "                \"\"\"\n",
    "            \n",
    "            \n",
    "        mean_loss = total_loss / (num_batches * num_mini_batches * self.minibatch_size)\n",
    "\n",
    "\n",
    "        P_over_q = torch.flatten(torch.stack(P_over_q))\n",
    "        P_over_pi = torch.flatten(torch.stack(P_over_pi))\n",
    "        pi_over_q = torch.flatten(torch.stack(pi_over_q))\n",
    "\n",
    "        ### now we compare the KL divergence betweend p and pi and p and q to perhaps replacce q \n",
    "        was_q_updated = False\n",
    "        z_hat_i = torch.mean(P_over_q)\n",
    "        z_hat_i_std = torch.std(P_over_q)\n",
    "        self.Z_moving_average = (self.iter*self.Z_moving_average + z_hat_i)/(self.iter+1)\n",
    "\n",
    "        tvd_p_pi = 0.5 * torch.sum(torch.abs(pi_over_q -P_over_q/ self.Z_moving_average))/(num_batches * num_mini_batches * self.minibatch_size)\n",
    "        tvd_p_q = 0.5 * torch.sum(torch.abs(1-P_over_q/ self.Z_moving_average))/(num_batches * num_mini_batches * self.minibatch_size)\n",
    "\n",
    "        dkl_p_pi = -torch.log(self.Z_moving_average) + torch.sum((P_over_q * torch.log(P_over_pi)))/(num_batches * num_mini_batches * self.minibatch_size * self.Z_moving_average)\n",
    "        dkl_p_q = -torch.log(self.Z_moving_average) + torch.sum((P_over_q * torch.log(P_over_q)))/(num_batches * num_mini_batches * self.minibatch_size * self.Z_moving_average)\n",
    "        \n",
    "        print('dkl_p_pi: ', dkl_p_pi)\n",
    "        print('dkl_p_q: ', dkl_p_q)\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.q_update_criterion == 'interval' :\n",
    "            if (self.iter+1) % self.q_update_interval == 0:\n",
    "                print(\"was_q_updated\")\n",
    "                self.ref_model.load_state_dict(self.model.state_dict())\n",
    "                was_q_updated = True\n",
    "        elif self.q_update_criterion in ['kld', 'tvd'] and (self.iter+1) % self.q_update_interval == 0:\n",
    "            if self.q_update_criterion == 'kld':\n",
    "                if dkl_p_pi < dkl_p_q:\n",
    "                    self.ref_model.load_state_dict(self.model.state_dict())\n",
    "                    if dkl_p_pi < self.min_kld:\n",
    "                        self.min_kld = dkl_p_pi\n",
    "                    was_q_updated = True\n",
    "                    print(\"updating q based on KL divergence\")\n",
    "                else :\n",
    "                    print (\"Worse KL divergence, not updating q\")\n",
    "            \n",
    "            if self.q_update_criterion == 'tvd':\n",
    "                \n",
    "                if tvd_p_pi < tvd_p_q:\n",
    "                    self.ref_model.load_state_dict(self.model.state_dict())\n",
    "                    if tvd_p_pi < self.min_tvd:\n",
    "                        self.min_tvd = tvd_p_pi\n",
    "                    was_q_updated = True\n",
    "                    print(\"updating q based on TVD\")\n",
    "                else :\n",
    "                    print (\"Worse TVD, not updating q\")\n",
    "        \n",
    "        train_stats['dkl_p_pi'] = dkl_p_pi\n",
    "        train_stats['dkl_p_q'] = dkl_p_q\n",
    "        train_stats['tvd_p_pi'] = tvd_p_pi\n",
    "        train_stats['tvd_p_q'] = tvd_p_q\n",
    "\n",
    "        train_stats['Z_moving_average'] = self.Z_moving_average\n",
    "        train_stats['min_kld'] = self.min_kld\n",
    "        train_stats['min_tvd'] = self.min_tvd\n",
    "        train_stats['loss'] = loss\n",
    "        train_stats['Z_mean'] = z_hat_i\n",
    "        train_stats['Z_std'] = z_hat_i_std\n",
    "\n",
    "        train_stats['q_updated?'] = was_q_updated\n",
    "        self.iter += 1\n",
    "        return train_stats\n",
    "        \"\"\"\n",
    "    def run_steps(self, num_steps, num_batches, num_mini_batches):\n",
    "            self.Module_Gen.batch_size = self.minibatch_size\n",
    "            train_history = []\n",
    "            for _ in range(num_steps):\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                train_stats = self.step(num_batches, num_mini_batches)\n",
    "                train_history.append(train_stats)\n",
    "\n",
    "\n",
    "            return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experiment:\n",
    "    exp_name: str\n",
    "    encod: str\n",
    "    keku: bool\n",
    "    train: bool\n",
    "    encoding_size: int = 13\n",
    "    edge_size: int = 3\n",
    "    encoding_option: str = 'charged'\n",
    "    compute_lambdas: bool = False\n",
    "\n",
    "exp = Experiment('GNN_baseline_3_modif', 'charged', True, False, 13, 3, 'charged', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def logP(smiles_list):\n",
    "    logP_values = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            logP_values.append(0)\n",
    "        else: \n",
    "            logp = Descriptors.MolLogP(mol)\n",
    "            if logp > 2.0 and logp < 2.5:\n",
    "                logP_values.append(1)\n",
    "            else:\n",
    "                logP_values.append(0)\n",
    "    return torch.tensor(logP_values)\n",
    "\n",
    "def QED(smiles_list):\n",
    "    qed_values = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            qed_values.append(0)\n",
    "        else: \n",
    "            qed = Descriptors.qed(mol)\n",
    "            if qed > 0.90:\n",
    "                qed_values.append(1)\n",
    "            else:\n",
    "                qed_values.append(0)\n",
    "    return torch.tensor(qed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best checkpoint number 1 of the epoch 2050.0 with a loss of 0.5107812829972882\n",
      "Loading best checkpoint number 1 of the epoch 2550.0 with a loss of 0.1984780294417413\n",
      "Loading best checkpoint number 2 of the epoch 2700.0 with a loss of 10.3904066518488\n",
      "..\\trained_models\\GNN_baseline_3_modif\\GNN1_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN2_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN3_split_two_without_node_embedding\\history_training\\checkpoint_2.pt\n",
      "Loading best checkpoint number 1 of the epoch 2050.0 with a loss of 0.5107812829972882\n",
      "Loading best checkpoint number 1 of the epoch 2550.0 with a loss of 0.1984780294417413\n",
      "Loading best checkpoint number 2 of the epoch 2700.0 with a loss of 10.3904066518488\n",
      "..\\trained_models\\GNN_baseline_3_modif\\GNN1_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN2_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN3_split_two_without_node_embedding\\history_training\\checkpoint_2.pt\n",
      "Loading best checkpoint number 1 of the epoch 2050.0 with a loss of 0.5107812829972882\n",
      "Loading best checkpoint number 1 of the epoch 2550.0 with a loss of 0.1984780294417413\n",
      "Loading best checkpoint number 2 of the epoch 2700.0 with a loss of 10.3904066518488\n",
      "..\\trained_models\\GNN_baseline_3_modif\\GNN1_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN2_baseline\\history_training\\checkpoint_1.pt ..\\trained_models\\GNN_baseline_3_modif\\GNN3_split_two_without_node_embedding\\history_training\\checkpoint_2.pt\n"
     ]
    }
   ],
   "source": [
    "GNNs_q = Model_GNNs(exp)\n",
    "GNNs_a = Model_GNNs(exp)\n",
    "GNNs_pi = Model_GNNs(exp)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Module_Gen = Sampling_Path_Batch(GNNs_q, GNNs_a, GNNs_pi, features = {'logP' : logP, 'QED' : QED}, lambdas = torch.Tensor([1.0, 1.0]), device = device, batch_size = 16, args=exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = GDCTrainer_path(Module_Gen,\n",
    "                          features = {'logP' : logP, 'QED' : QED},\n",
    "                          desired_moments= {'logP' : 1.0, 'QED' : 1.0},\n",
    "                          q_update_criterion='kld',\n",
    "                          lr = 1e-4,\n",
    "                          minibatch_size = 16,\n",
    "                          batch_size = 16,\n",
    "                          min_nabla_lambda = 1e-4,\n",
    "                          lambdas=torch.Tensor([7.8309, 8.3757])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:02<00:00,  6.10s/it]\n",
      " 25%|██▌       | 1/4 [02:02<06:06, 122.09s/it][15:49:22] Explicit valence for atom # 18 O, 3, is greater than permitted\n",
      "[15:49:22] Explicit valence for atom # 18 O, 3, is greater than permitted\n",
      "100%|██████████| 20/20 [01:56<00:00,  5.84s/it]\n",
      " 50%|█████     | 2/4 [03:58<03:57, 118.96s/it][15:50:04] Explicit valence for atom # 22 F, 2, is greater than permitted\n",
      "[15:50:05] Explicit valence for atom # 22 F, 2, is greater than permitted\n",
      "100%|██████████| 20/20 [01:55<00:00,  5.75s/it]\n",
      "100%|██████████| 20/20 [01:53<00:00,  5.69s/it]\n",
      "100%|██████████| 4/4 [07:47<00:00, 116.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkl_p_pi:  tensor(4.4258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "dkl_p_q:  tensor(4.1825, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:00<00:00,  6.03s/it]\n",
      "100%|██████████| 20/20 [01:55<00:00,  5.76s/it]\n",
      "100%|██████████| 20/20 [01:56<00:00,  5.83s/it]\n",
      "100%|██████████| 20/20 [02:00<00:00,  6.03s/it]\n",
      "100%|██████████| 4/4 [07:53<00:00, 118.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkl_p_pi:  tensor(4.6899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "dkl_p_q:  tensor(4.1784, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:57<00:00,  5.86s/it]\n",
      " 25%|██▌       | 1/4 [01:57<05:51, 117.26s/it][16:03:47] Explicit valence for atom # 21 O, 3, is greater than permitted\n",
      "[16:03:47] Explicit valence for atom # 21 O, 3, is greater than permitted\n",
      "100%|██████████| 20/20 [02:04<00:00,  6.20s/it]\n",
      " 50%|█████     | 2/4 [04:01<04:02, 121.27s/it][16:07:06] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "[16:07:06] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "100%|██████████| 20/20 [01:56<00:00,  5.84s/it]\n",
      " 75%|███████▌  | 3/4 [05:58<01:59, 119.24s/it][16:08:45] \n",
      "\n",
      "****\n",
      "Pre-condition Violation\n",
      "attempt to add self-bond\n",
      "Violation occurred on line 333 in file C:\\rdkit\\build\\temp.win-amd64-cpython-310\\Release\\rdkit\\Code\\GraphMol\\RWMol.cpp\n",
      "Failed Expression: atomIdx1 != atomIdx2\n",
      "****\n",
      "\n",
      " 60%|██████    | 12/20 [01:16<00:50,  6.34s/it]\n",
      " 75%|███████▌  | 3/4 [07:14<02:24, 144.73s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pre-condition Violation\n\tattempt to add self-bond\n\tViolation occurred on line 333 in file Code\\GraphMol\\RWMol.cpp\n\tFailed Expression: atomIdx1 != atomIdx2\n\tRDKIT: 2022.09.5\n\tBOOST: 1_78\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Trainer\u001b[39m.\u001b[39;49mrun_steps(\u001b[39m1000\u001b[39;49m, \u001b[39m4\u001b[39;49m, \u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 290\u001b[0m, in \u001b[0;36mGDCTrainer_path.run_steps\u001b[1;34m(self, num_steps, num_batches, num_mini_batches)\u001b[0m\n\u001b[0;32m    288\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m    289\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m--> 290\u001b[0m     train_stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(num_batches, num_mini_batches)\n\u001b[0;32m    291\u001b[0m     train_history\u001b[39m.\u001b[39mappend(train_stats)\n\u001b[0;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m train_history\n",
      "Cell \u001b[1;32mIn[2], line 155\u001b[0m, in \u001b[0;36mGDCTrainer_path.step\u001b[1;34m(self, num_batches, num_mini_batches)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_3_2\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mModule_Gen\u001b[39m.\u001b[39mfull_generation()\n\u001b[1;32m--> 155\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mModule_Gen\u001b[39m.\u001b[39;49mconvert_to_smiles()\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mModule_Gen\u001b[39m.\u001b[39mcompute_features()\n\u001b[0;32m    158\u001b[0m exponents, all_features_values, q_value, a_value, pi_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mModule_Gen\u001b[39m.\u001b[39mget_all()\n",
      "File \u001b[1;32mc:\\Users\\goupi\\OneDrive - CentraleSupelec\\VSCODE\\Siena\\MolecularGen\\Molgen\\MolGen\\ReinforcementTuning\\generation.py:540\u001b[0m, in \u001b[0;36mconvert_to_smiles\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m graph_list \u001b[39m=\u001b[39m extract_all_graphs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmol_graphs_list)\n\u001b[0;32m    539\u001b[0m smiles_list \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 540\u001b[0m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m graph_list:\n\u001b[0;32m    541\u001b[0m     smiles_list\u001b[39m.\u001b[39mappend(tensor_to_smiles(g\u001b[39m.\u001b[39mx, g\u001b[39m.\u001b[39medge_index, g\u001b[39m.\u001b[39medge_attr, edge_mapping\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkekulized\u001b[39m\u001b[39m'\u001b[39m, encoding_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcharged\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmiles_list \u001b[39m=\u001b[39m smiles_list\n",
      "File \u001b[1;32mc:\\Users\\goupi\\OneDrive - CentraleSupelec\\VSCODE\\Siena\\MolecularGen\\Molgen\\MolGen\\DataPipeline\\preprocessing.py:475\u001b[0m, in \u001b[0;36mtensor_to_smiles\u001b[1;34m(node_features, edge_index, edge_attr, edge_mapping, encoding_type)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[39m# RDKit ignores attempts to add a bond that already exists,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[39m# so we need to check if the bond exists before we add it\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[39mif\u001b[39;00m mol\u001b[39m.\u001b[39mGetBondBetweenAtoms(start\u001b[39m.\u001b[39mitem(), end\u001b[39m.\u001b[39mitem()) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m         mol\u001b[39m.\u001b[39;49mAddBond(start\u001b[39m.\u001b[39;49mitem(), end\u001b[39m.\u001b[39;49mitem(), bond_type)\n\u001b[0;32m    477\u001b[0m \u001b[39m# Convert the molecule to SMILES\u001b[39;00m\n\u001b[0;32m    478\u001b[0m smiles \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39mMolToSmiles(mol)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Pre-condition Violation\n\tattempt to add self-bond\n\tViolation occurred on line 333 in file Code\\GraphMol\\RWMol.cpp\n\tFailed Expression: atomIdx1 != atomIdx2\n\tRDKIT: 2022.09.5\n\tBOOST: 1_78\n"
     ]
    }
   ],
   "source": [
    "Trainer.run_steps(1000, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
