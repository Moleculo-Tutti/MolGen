{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import concurrent\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from torch_scatter import scatter_max, scatter_add\n",
    "\n",
    "from DataPipeline.preprocessing import process_encode_graph, get_subgraph_with_terminal_nodes_step\n",
    "from DataPipeline.preprocessing import node_encoder\n",
    "from Model.GNN1 import ModelWithEdgeFeatures as GNN1\n",
    "from Model.GNN1 import ModelWithNodeConcat as GNN1_node_concat\n",
    "from Model.GNN2 import ModelWithEdgeFeatures as GNN2\n",
    "from Model.GNN2 import ModelWithNodeConcat as GNN2_node_concat\n",
    "from Model.GNN3 import ModelWithEdgeFeatures as GNN3\n",
    "from Model.GNN3 import ModelWithgraph_embedding_modif as GNN3_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORED_SAVING_DIR = Path('.') / 'generated_mols' / 'scored'\n",
    "ZINC_DATA_PATH = SCORED_SAVING_DIR / 'zinc_scored_filtered.csv'\n",
    "df_zinc = pd.read_csv(ZINC_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_smiles(node_features, edge_index, edge_attr, edge_mapping = 'aromatic', encoding_type = 'charged'):\n",
    "    # Create an empty editable molecule\n",
    "    mol = Chem.RWMol()\n",
    "\n",
    "    # Define atom mapping\n",
    "    if encoding_type == 'charged':\n",
    "        \n",
    "        atom_mapping = {\n",
    "            0: ('C', 0),\n",
    "            1: ('N', 0),\n",
    "            2: ('N', 1),\n",
    "            3: ('N', -1),\n",
    "            4: ('O', 0),\n",
    "            5: ('O', -1),\n",
    "            6: ('F', 0),\n",
    "            7: ('S', 0),\n",
    "            8: ('S', -1),\n",
    "            9: ('Cl', 0),\n",
    "            10: ('Br', 0),\n",
    "            11: ('I', 0)\n",
    "        }\n",
    "\n",
    "    elif encoding_type == 'polymer':\n",
    "        atom_mapping = {\n",
    "            0: ('C', 0),\n",
    "            1: ('N', 0),\n",
    "            2: ('O', 0),\n",
    "            3: ('F', 0),\n",
    "            4: ('Si', 0),\n",
    "            5: ('P', 0),\n",
    "            6: ('S', 0)}\n",
    "\n",
    "    # Add atoms\n",
    "    for atom_feature in node_features:\n",
    "        atom_idx = atom_feature[:12].argmax().item()\n",
    "        atom_symbol, charge = atom_mapping.get(atom_idx)\n",
    "        atom = Chem.Atom(atom_symbol)\n",
    "        atom.SetFormalCharge(charge)\n",
    "        mol.AddAtom(atom)\n",
    "\n",
    "    # Define bond type mapping\n",
    "    if edge_mapping == 'aromatic':\n",
    "        bond_mapping = {\n",
    "            0: Chem.rdchem.BondType.AROMATIC,\n",
    "            1: Chem.rdchem.BondType.SINGLE,\n",
    "            2: Chem.rdchem.BondType.DOUBLE,\n",
    "            3: Chem.rdchem.BondType.TRIPLE,\n",
    "        }\n",
    "    elif edge_mapping == 'kekulized':\n",
    "        bond_mapping = {\n",
    "            0: Chem.rdchem.BondType.SINGLE,\n",
    "            1: Chem.rdchem.BondType.DOUBLE,\n",
    "            2: Chem.rdchem.BondType.TRIPLE,\n",
    "        }\n",
    "\n",
    "    # Add bonds\n",
    "    for start, end, bond_attr in zip(edge_index[0], edge_index[1], edge_attr):\n",
    "        bond_type_idx = bond_attr[:4].argmax().item()\n",
    "        bond_type = bond_mapping.get(bond_type_idx)\n",
    "\n",
    "        # RDKit ignores attempts to add a bond that already exists,\n",
    "        # so we need to check if the bond exists before we add it\n",
    "        if mol.GetBondBetweenAtoms(start.item(), end.item()) is None:\n",
    "            mol.AddBond(start.item(), end.item(), bond_type)\n",
    "\n",
    "    # Convert the molecule to SMILES\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "\n",
    "    return smiles\n",
    "\n",
    "def extract_all_graphs(batch):\n",
    "    all_graphs = []\n",
    "    nb_graphs = batch.batch.max().item() + 1\n",
    "\n",
    "    for i in range(nb_graphs):\n",
    "        # Create a mask of booleans\n",
    "        mask = batch.batch == i\n",
    "        \n",
    "        # Extract all the node features that correspond to the i-th graph\n",
    "        subgraph_x = batch.x[mask]\n",
    "        # Create a mapping of the corresponding indices from the big graph to the individual graph\n",
    "\n",
    "        indices_mapping = {j.item(): k for k, j in enumerate(torch.where(mask)[0])}\n",
    "        mapping_func = np.vectorize(indices_mapping.get)\n",
    "\n",
    "        # Extract all the edges that correspond to the i-th graph\n",
    "        edge_mask = mask[batch.edge_index[0]] & mask[batch.edge_index[1]]\n",
    "\n",
    "        if edge_mask.sum() == 0:\n",
    "            subgraph_edge_index = torch.tensor([], dtype=torch.long)\n",
    "        else:\n",
    "            subgraph_edge_index = torch.tensor(mapping_func(batch.edge_index[:, edge_mask].cpu().numpy()), dtype=torch.long)\n",
    "\n",
    "        # Extract all the edge features that correspond to the i-th graph\n",
    "\n",
    "        \n",
    "        if batch.edge_attr is not None:\n",
    "            subgraph_edge_attr = batch.edge_attr[edge_mask]\n",
    "        else:\n",
    "            subgraph_edge_attr = None\n",
    "\n",
    "        # Construct the subgraph\n",
    "        subgraph = Data(x=subgraph_x, edge_index=subgraph_edge_index, edge_attr=subgraph_edge_attr)\n",
    "        # Append the subgraph to the list\n",
    "        all_graphs.append(subgraph)\n",
    "\n",
    "    return all_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_subgraph_ZINC(pd_dataframe, start_size):\n",
    "    indice = random.choice(pd_dataframe.index)\n",
    "    smiles_str = pd_dataframe.loc[indice, 'smiles']\n",
    "\n",
    "    torch_graph = process_encode_graph(smiles_str, encoding_option='charged', kekulize=True)\n",
    "    subgraph_data, terminal_node_info, id_map = get_subgraph_with_terminal_nodes_step(torch_graph, start_size, impose_edges=True)\n",
    "\n",
    "    return subgraph_data, terminal_node_info, id_map\n",
    "\n",
    "def create_batch_from_zinc(pd_dataframe, batch_size, start_size, encoding_option='reduced'):\n",
    "    graphs = []\n",
    "    for _ in range(batch_size):\n",
    "        subgraph_data, terminal_node_info, id_map = sample_random_subgraph_ZINC(pd_dataframe, start_size)\n",
    "        graphs.append(subgraph_data)\n",
    "    return Batch.from_data_list(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FinalPipeline.utils import GenerationModule, tensor_to_smiles\n",
    "def convert_to_smiles(graph, kekulize=True, encoding_type='charged'):\n",
    "    smiles = []\n",
    "    for g in graph:\n",
    "        smiles.append(tensor_to_smiles(g.x, g.edge_index, g.edge_attr, edge_mapping='kekulized', encoding_type=encoding_type))\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def generate_scaffolds(nb, batch_size):\n",
    "    smiles_scaffolds = []\n",
    "    for _ in tqdm(range(nb)):\n",
    "        graph_batch = create_batch_from_zinc(df_zinc, batch_size, 3)\n",
    "        graph_list = extract_all_graphs(graph_batch)\n",
    "        smiles_scaffolds.extend(convert_to_smiles(graph_list, kekulize=True, encoding_type='charged'))\n",
    "\n",
    "    return smiles_scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [41:46<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "scaffolds_1000000 = generate_scaffolds(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:16<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "scaffolds = generate_scaffolds(100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique scaffolds: 139\n"
     ]
    }
   ],
   "source": [
    "# Count of unique scaffolds\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "scaffolds_counter = Counter(scaffolds)\n",
    "print(f'Number of unique scaffolds: {len(scaffolds_counter)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique scaffolds: 188\n"
     ]
    }
   ],
   "source": [
    "# Count of unique scaffolds1000000\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "scaffolds_counter_1000000 = Counter(scaffolds_1000000)\n",
    "print(f'Number of unique scaffolds: {len(scaffolds_counter_1000000)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
